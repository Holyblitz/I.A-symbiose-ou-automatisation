# **Rapport : Impacts du rapport usagers-LLM **

###### Introduction– cadre général

1.1 Contexte et justification

L'intelligence artificielle (IA) suscite aujourd'hui autant d'enthousiasme que d'inquiétudes et avec celle ci des discours très radicaux sur son bénéfice ou maléfice (comme "l'I.A va tous nous remplacer"). Dans un contexte de numérisation accélérée des économies, la généralisation des modèles d'IA générative (comme les LLM) bouleverse les usages professionnels, éducatifs, et sociaux et même peut être la structure de nos sociétés. Ce rapport propose une analyse des impacts socio-économiques positifs et négatifs de l'IA dans les pays de l'OCDE, en articulant les données quantitatives disponibles à une analyse qualitative des usages, des perceptions et des dynamiques en cours.

1.2 Données clés d'ouverture

Niveau d'éducation supérieur (source : OCDE 2022)

-En moyenne, 40 % des 25‑64 ans dans les pays de l’OCDE possèdent un diplôme du supérieur.

-Cette proportion dépasse 50 % chez les 25‑34 ans dans certains pays (Canada, Estonie).

En clair : Ces chiffres donnent une idée du cadre éducatif du potentiel d’intégration de l’IA dans la société et le monde du travail. **Un niveau de formation élevé augmente la capacité d’adoption des outils IA.** Point qui n'est pas spécifique aux profils issus de grandes études mais tout de même assez révélateurs de la tendance actuelle.

Adoption de l’IA par les entreprises (source : Commission européenne, 2024)

-13,5 % des entreprises européennes de plus de 10 salariés utilisent l’IA en 2024.

+5,5 points en un an.

Jusqu’à 41 % dans les grandes entreprises.

Donc: **L’usage croît rapidement**, notamment dans les secteurs technologiques, mais reste modéré dans les TPE et PME pour l'instant.

1.3 Objectifs de la partie 1.

Cartographier les effets actuels de l’IA sur le monde du travail, l’éducation, les inégalités.

Distinguer les usages par automatisation et par assistance augmentée.

Identifier les perceptions réelles chez les professionnels (enseignants, managers, syndicats).

Proposer une réflexion sur les conditions d’un développement éthique et bénéfique de l’IA.

## Partie 1 : L'automatisation, fantasme médiatique contre réalité d'usage des assistants IA

« L’intelligence artificielle va supprimer 300 millions d’emplois »— Le Figaro, mars 2024

Commentaire : Ce chiffre est repris **sans source directe ni nuance**. Il s’appuie sur un rapport de Goldman Sachs souvent mal interprété. Aucun secteur ou pays n’est spécifié, ce qui rend l’info peu exploitable.

« Avec ChatGPT, j’ai perdu mon job en 2 semaines »— Le Parisien, 8 juin 2025

Commentaire : L’article relate le cas isolé d’un assistant administratif, **sans vérifier si le poste était déjà fragilisé**. Aucune enquête sur les usages réels de l’IA dans la société n’est menée.

À noter : Sur YouTube, tapez simplement “intelligence artificielle  : vous verrez que, dans la majorité des cas, l’IA est **un sujet qui est utilisé pour vendre des formations  par la peur d'être remplacé**. pour des raisons de droits d'auteurs je suis limité dans mon descriptif, mais je fais confiance à votre sagacité pour comprendre.

En résumé

Les chiffres et témoignages collectés montrent une réalité nuancée. L'IA, aujourd'hui, est surtout :

Un assistant dans des tâches cognitives ou répétitives

Un outil complémentaire, notamment dans l'enseignement ou la bureautique

Un enjeu stratégique dans certaines entreprises, mais pas un moteur de licenciement massif

Nous allons d'ailleurs voir ce point immédiatement:

## Constat qualitatif : L’usage réel de l’I.A dans les environnements éducatifs et professionnels

Contrairement aux récits alarmistes relayés dans certains médias, l’usage quotidien de l’intelligence artificielle, tel qu’il émerge des témoignages de terrain, révèle une tout autre dynamique : **celle d’une collaboration**, bien plus que d’une substitution.

### Éducation : des assistants plus que des remplaçants

**Les enseignants** utilisent les LLMs (comme ChatGPT ou Gemini) pour :

-Générer des supports de cours personnalisés ;

-Créer des quiz, des résumés, des corrigés-types ;

-Adapter les contenus pédagogiques au niveau réel des élèves.

> *« Je m’en sers pour adapter mes contenus à des élèves en difficulté, ou pour reformuler des consignes. Ça me fait gagner du temps. »*  
> — Professeur de lycée, académie de Lille.

**Les étudiants** les mobilisent pour :

-Reformuler des notions incomprises ;

-Se faire expliquer des concepts complexes de manière synthétique ;

-Rédiger des trames ou brainstormer des idées de projets.

> *« Pour mon mémoire, ChatGPT m’a aidé à organiser mes idées. Pas à tricher, juste à structurer ma pensée. »*  
> — Étudiant en licence de droit, Paris Nanterre.

Fait marquant: aucun témoignage ne décrit une **mise à l’écart de l’enseignant**. L’IA est utilisée comme **accélérateur pédagogique**, pas comme substitut.

---

### Entreprises : l’IA comme levier de productivité ciblée

**Les managers** s’en servent pour :

-Rédiger ou relire des e-mails, synthétiser des rapports ;

-Prototyper des idées (ex. prompts pour générateurs d’images ou code) ;

-Appuyer la prise de décision par des résumés de données.

> *« J’utilise GPT pour résumer mes rapports de réunions. Ça me permet de garder les points essentiels sans passer une heure dessus. »*  
> — Manager en entreprise de services numériques (ESN), Lyon.

**Les employés techniques** (devs, analystes, etc.) déclarent l’utiliser pour :

-Corriger ou expliquer du code ;

-Automatiser des tâches chronophages et répétitives;

-Créer des scripts ou des tests unitaires plus rapidement.

> *« Je ne code plus jamais sans. Il me fait gagner deux heures par jour, mais je garde toujours la main sur les décisions. »*  
> — Développeur Python, Toulouse.

**Point commun majeur** : l’IA est rarement « lâchée en autonomie » ; elle agit sous **supervision humaine constante**.

---

Notons que les seules introductions d'I.A "automatisées" seraient alors les I.A utilisées par les services publics.

Nous avons tous entendus parler, par exemple, de ces I.A de reconnaissance faciale en Chine ou ces I.A en France qui relèvent nos plaques d'immatriculation afin de nous verbaliser.

Il est ironique de constater que l'instance qui automatise le plus à l'aide de l'I.A est celle qui semble le plus la redouter.

## Partie 2 : Vulgarisation des LLM et hypothèse épistémologique

### Qu’est-ce qu’une I.A générative ? Et en quoi les LLM en font partie ?

D'abord, il est important de remettre les choses dans leurs contexte. En 2022 ce que le monde a découvert à grande échelle est juste un type d'I.A! **Trop de gens pensent depuis lors que chat GPT est l'I.A.** L'I.A est une technique imaginée depuis les années 1960. La démarche intellectuelle était, suite au développement de l'outil informatique, de transposer les actions de l'esprit humain dans des composantes matérielles ou logicielles. Et, **à ce titre chat GPT est une I.A générative**, comme claude ou Gémini. 

Une **I.A générative** est un type d’intelligence artificielle capable de **créer du contenu nouveau** à partir de données d'entraînement : texte, images, musique, code, etc.

Contrairement à une I.A classique qui se contente de **classer, détecter ou prédire** (par exemple : reconnaître un visage, détecter une fraude), une I.A générative **produit** quelque chose de neuf : un texte, une image, une fiction ou même un design.

Il fait cela a partir de ce qu'on appelle un Token.Un token est une unité de base de langage que l'IA utilise pour comprendre et générer du texte. Pour mieux faire comprendre ce qu'est un token ce serait comme Un petit morceau de texte que le LLM utilise pour comprendre le langage.                                                                         													 Par exemple Un mot, comme 'chat', est un exemple de token

A noter: Un token **n’est pas toujours un mot complet** (par exemple, « extraordinaire » peut être divisé en plusieurs tokens).

Un **LLM** (comme GPT ou Claude) est une **I.A générative spécialisée dans le langage**. Il ne se contente pas d’analyser du texte : il **génère** des phrases, réponses, idées, en suivant des probabilités d’association entre les mots (ou token)

Ce qui fait qu'un LLM, quand il vous répond, n'essaie pas de décrire une réalité. **Il calcule simplement les mots les plus probables pour vous répondre en fonction des données à sa disposition.** Remarque qui sera très importante dans la suite de notre rapport.

### 2.1 Comment fonctionne un LLM (modèle de langage de grande taille) ?

Un **LLM** (Large Language Model) est une intelligence artificielle entraînée sur des milliards de mots, phrases, et textes issus d'Internet, de livres, d’articles, de forums. Son objectif est simple mais puissant : **prédire le mot suivant le plus probable dans une séquence donnée**.

Pour cela, il transforme chaque mot en **vecteur mathématique** (via des embeddings), apprend les relations statistiques entre les mots et, par couches successives (transformers), affine ses prédictions. Il n’a pas de « conscience », mais il peut produire des réponses d’une précision remarquable grâce à la profondeur de son entraînement.

### 2.2 Limites fondamentales : probabilité n'est pas compréhension

Un LLM **ne pense pas**. Il **modélise des structures probables** de langage humain. Il ne comprend pas ce qu'est une table ; il sait que le mot « table » est souvent suivi de « en bois » ou « dans la salle à manger ».

Il peut donc sembler intelligent, sans l’être. Mais cette **illusion de compréhension** permet parfois des usages pertinents, surtout lorsque le LLM est bien utilisé.

### 2.3 Un parallèle épistémologique avec la pensée humaine

Les humains n'accèdent pas directement à la vérité. Ils créent des **théories, des modèles** pour approcher le réel : en science, en philosophie, en économie. Ces modèles évoluent selon des critères historiques, logiques, sociaux, technologiques ou même naturels.

Or, ces modèles utilisent le **langage** : ce sont des phrases, des hypothèses, des raisonnements. L’humain lui aussi manipule des symboles pour s’approcher d’un monde qu’il ne peut pas totalement saisir.

En somme, comme le pensais kuhn, une théorie scientifique ou, plus largement une connaissance, **décrit le réel avec une forte probabilité**, probabilité validée par l'expérience.

Ainsi nous pouvons formuler une hypothèse:

> **Hypothèse** : Si l’humain approche la vérité par modélisation, un LLM, bien utilisé, pourrait s’en approcher également. Non par compréhension, mais par **truchement d’usage collaboratif**.

### 2.4 L’importance de l’usage dans l’amélioration des résultats

Un LLM seul, en lecture froide d’un texte, ne s’améliore pas. Mais un LLM **sollicité activement par un utilisateur**, qui donne du contexte,critique, revient sur les réponses, crée un processus **co-constructif**, devient potentiellement plus pertinent, plus adapté.

Dans cette hypothèse la performance du LLM ne dépendrait pas uniquement de sa puissance ou de son financement, mais aussi du **niveau d’engagement de l’utilisateur**.

Ainsi, dans la partie 3 nous nous consacrerons à l’impact de l’usage humain sur les performances des LLM, avec étude qualitative et pistes d’approfondissement. Partie passionnante à étudier mais qui ne peut être abordée de manière complète par une étude individuelle.



## Partie 3 — Pourquoi la question se pose-t-elle ?

### 1. Trois constats visuels qui contredisent une lecture linéaire de la performance

**Investissements :**

![](/home/romain/port_folio/P1_IA/graphs/investissements_llm.png)

*On observe des écarts colossaux d’investissement entre les LLM. ChatGPT surclasse largement ses concurrents sur ce plan avec près de 58 milliards de dollars cumulés, tandis que Claude se situe sous les 5 milliards.*

**Structure technique (capacité contextuelle) :**

![](/home/romain/port_folio/P1_IA/graphs/capacite_llm.png)

*Pourtant, ce n’est pas OpenAI, mais bien Gemini qui dispose de la capacité contextuelle la plus élevée (1 million de tokens), signe d’une conception structurelle pensée autrement.*

**Utilisateurs actifs :**

![](/home/romain/port_folio/P1_IA/graphs/utilisateurs_llm.png)

*Enfin, Claude, pourtant le moins financé et le moins utilisé, obtient parfois des résultats conceptuels supérieurs. On est donc contraint de constater que performance ne veut pas dire ni investissement ni volume d’usage, même si ces derniers jouent évidemment.*

### 3.2. Deux facteurs majeurs émergent : entraînement et usage

*Ce que révèlent ces écarts, c’est que la qualité d’un LLM dépend d’abord de l’entraînement (qualité des données, structure du modèle, méthode d’alignement), et ensuite de l’usage que l’on en fait.*

### 3.3. Trois modèles, trois philosophies

- **ChatGPT** : la **polyvalence** maximale (utilisation massive, entraînement généraliste, multimodalité)
- **Gemini** : la **structure intégrée** (intégration à Google, recherche de cohérence technique)
- **Claude** : la **rigueur conceptuelle** (philosophie "constitutional AI", entraînement qualitatif)

*Ces trois orientations illustrent des conceptions différentes de ce que doit être un assistant intelligent. Elles traduisent des logiques de développement, mais aussi des visions épistémiques du rôle de l’IA.*

### 3.4. Hypothèse épistémologique élargie

> *"Si nous connaissons par modèles, alors un LLM peut-il s'améliorer ou régresser par le biais du truchement — c’est-à-dire par sa propre structuration inductive ?"*

*Mais allons plus loin : peut-il aussi régresser ou dériver à cause de l’usage qu’on en fait ?*

### 3.5. Une hypothèse expérimentale concrète

*Si 13 % des requêtes envoyées à ChatGPT sont liées à l’érotisme, soit à des structures langagières ancrées dans le fantasme — donc détachées du réel — peut-on penser que cela modifie, même partiellement, sa capacité à générer du langage structuré, cohérent et *ancré ?* (ce n'est pas une hypothèse gratuite: Jancovici émettait ce chiffre sur la chaîne you-tube 'éthique et tac')

### 3.6. Ouverture vers un travail collectif

*Il ne serait pas raisonnable de répondre seul à cette question. Elle suppose des moyens, des protocoles, et une équipe. Mais elle est posée, et justifie une suite à ce rapport, suite à laquelle nous allons tenter de répondre avec des moyens individuels dans les parties deux et trois de notre travail.* A ce titre nous allons simplement nous attarder dans les parties 2 et 3 a la perspective collaborative de l'I.A.



*Index*:

sources utilisées pour les graphiques:

- The New York Times, *Microsoft Invests $10 Billion in OpenAI*, janvier 2023. page archivée sur archive.org
   https://www.nytimes.com/2023/01/23/technology/microsoft-invests-10-billion-openai.html
- The Information, *OpenAI Costs May Top $700,000 a Day to Run ChatGPT*, 2023.
- The Verge, *Amazon to invest up to $4 billion in Anthropic*, septembre 2023. Page archivée sur Archive.org
   https://www.theverge.com/2023/9/25/23889175/amazon-anthropic-investment-ai-claude
- TechCrunch, *Anthropic expands partnership with Google*, décembre 2023. page archivée sur archive.org
   https://techcrunch.com/2023/12/28/anthropic-google-cloud-ai-infrastructure/
- Google Blog, *Next-generation Gemini model*, février 2024.
   https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/

**Capacité contextuelle (tokens) :**

- OpenAI, *GPT-4 Turbo context length*, section “Pricing & specs”.
   https://openai.com/pricing
- Anthropic, *Introducing Claude 3*, mars 2024.
   https://www.anthropic.com/news/claude-3
- Google Blog (cf. ci-dessus pour Gemini 1.5 context window)

**Utilisateurs estimés :**

- OpenAI, *ChatGPT reaches 180M users*, janvier 2024.
- Claude et Gemini : extrapolations issues des données disponibles publiquement.